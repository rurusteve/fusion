{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, StandardScaler\n",
    "\n",
    "from config import CONFIG_BY_KEY\n",
    "from data_loader import DataLoader\n",
    "from data_loader import DataHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h]\n",
      "                             [--config-key {,t,a,v,ta,tv,av,tav,t-c,t-author,tv-c,tv-author,i-t,i-a,i-v,i-ta,i-tv,i-av,i-tav,i-t-c,i-t-author,i-ta-c,i-ta-author}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\Ruru\\AppData\\Roaming\\jupyter\\runtime\\kernel-21b2d5cf-8f1d-4c1d-9d19-e66b806aaaa5.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "RESULT_FILE = \"./output/{}.json\"\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config-key', default='', choices=list(CONFIG_BY_KEY.keys()))\n",
    "    return parser.parse_args()\n",
    "\n",
    "args = parse_args()\n",
    "print(\"Args:\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-36ec2bfc03d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCONFIG_BY_KEY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "config = CONFIG_BY_KEY[args.config_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = DataLoader(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_train(train_input, train_output):\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler() if config.svm_scale else FunctionTransformer(lambda x: x, validate=False),\n",
    "        svm.SVC(C=config.svm_c, gamma='scale', kernel='rbf')\n",
    "    )\n",
    "\n",
    "    return clf.fit(train_input, np.argmax(train_output, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_test(clf, test_input, test_output):\n",
    "\n",
    "    probas = clf.predict(test_input)\n",
    "    y_pred = probas\n",
    "    y_true = np.argmax(test_output, axis=1)\n",
    "\n",
    "    # To generate random scores\n",
    "    # y_pred = np.random.randint(2, size=len(y_pred))\n",
    "\n",
    "    # To generate majority baseline\n",
    "    # y_pred = [0]*len(y_pred)\n",
    "    \n",
    "    result_string = classification_report(y_true, y_pred, digits=3)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(result_string)\n",
    "    return classification_report(y_true, y_pred, output_dict=True, digits=3), result_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIO(train_index, test_index):\n",
    "\n",
    "    # Prepare data\n",
    "    train_input, train_output = data.getSplit(train_index)\n",
    "    test_input, test_output = data.getSplit(test_index)\n",
    "\n",
    "    datahelper = DataHelper(train_input, train_output, test_input, test_output, config, data)\n",
    "\n",
    "    train_input = np.empty((len(train_input), 0))\n",
    "    test_input = np.empty((len(test_input), 0))\n",
    "\n",
    "    if config.use_target_text:\n",
    "\n",
    "        if config.use_bert:\n",
    "            train_input = np.concatenate([train_input, datahelper.getTargetBertFeatures(mode='train')], axis=1)\n",
    "            test_input = np.concatenate([test_input, datahelper.getTargetBertFeatures(mode='test')], axis=1)\n",
    "        else:\n",
    "            train_input = np.concatenate([train_input,\n",
    "                                          np.array([datahelper.pool_text(utt)\n",
    "                                                    for utt in datahelper.vectorizeUtterance(mode='train')])], axis=1)\n",
    "            test_input = np.concatenate([test_input,\n",
    "                                         np.array([datahelper.pool_text(utt)\n",
    "                                                   for utt in datahelper.vectorizeUtterance(mode='test')])], axis=1)\n",
    "\n",
    "    if config.use_target_video:\n",
    "        train_input = np.concatenate([train_input, datahelper.getTargetVideoPool(mode='train')], axis=1)\n",
    "        test_input = np.concatenate([test_input, datahelper.getTargetVideoPool(mode='test')], axis=1)\n",
    "\n",
    "    if config.use_target_audio:\n",
    "        train_input = np.concatenate([train_input, datahelper.getTargetAudioPool(mode='train')], axis=1)\n",
    "        test_input = np.concatenate([test_input, datahelper.getTargetAudioPool(mode='test')], axis=1)\n",
    "\n",
    "    if train_input.shape[1] == 0:\n",
    "        print(\"Invalid modalities\")\n",
    "        exit(1)\n",
    "\n",
    "    # Aux input\n",
    "\n",
    "    if config.use_author:\n",
    "        train_input_author = datahelper.getAuthor(mode=\"train\")\n",
    "        test_input_author =  datahelper.getAuthor(mode=\"test\")\n",
    "\n",
    "        train_input = np.concatenate([train_input, train_input_author], axis=1)\n",
    "        test_input = np.concatenate([test_input, test_input_author], axis=1)\n",
    "\n",
    "    if config.use_context:\n",
    "        if config.use_bert:\n",
    "            train_input_context = datahelper.getContextBertFeatures(mode=\"train\")\n",
    "            test_input_context =  datahelper.getContextBertFeatures(mode=\"test\")\n",
    "        else:\n",
    "            train_input_context = datahelper.getContextPool(mode=\"train\")\n",
    "            test_input_context =  datahelper.getContextPool(mode=\"test\")\n",
    "\n",
    "        train_input = np.concatenate([train_input, train_input_context], axis=1)\n",
    "        test_input = np.concatenate([test_input, test_input_context], axis=1)\n",
    "\n",
    "    \n",
    "    train_output = datahelper.oneHotOutput(mode=\"train\", size=config.num_classes)\n",
    "    test_output = datahelper.oneHotOutput(mode=\"test\", size=config.num_classes)\n",
    "\n",
    "    return train_input, train_output, test_input, test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSpeakerIndependent(model_name=None):\n",
    "\n",
    "    config.fold = \"SI\"\n",
    "    \n",
    "    (train_index, test_index) = data.getSpeakerIndependent()\n",
    "    train_input, train_output, test_input, test_output = trainIO(train_index, test_index)\n",
    "\n",
    "    clf = svm_train(train_input, train_output)\n",
    "    svm_test(clf, test_input, test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSpeakerDependent(model_name=None):\n",
    "    \n",
    "    # Load data\n",
    "    data = DataLoader(config)\n",
    "\n",
    "    # Iterating over each fold\n",
    "    results=[]\n",
    "    for fold, (train_index, test_index) in enumerate(data.getStratifiedKFold()):\n",
    "\n",
    "        # Present fold\n",
    "        config.fold = fold+1\n",
    "        print(\"Present Fold: {}\".format(config.fold))\n",
    "\n",
    "        train_input, train_output, test_input, test_output = trainIO(train_index, test_index)\n",
    "\n",
    "        clf = svm_train(train_input, train_output)\n",
    "        result_dict, result_str = svm_test(clf, test_input, test_output)\n",
    "\n",
    "        results.append(result_dict)\n",
    "\n",
    "    # Dumping result to output\n",
    "    if not os.path.exists(os.path.dirname(RESULT_FILE)):\n",
    "        os.makedirs(os.path.dirname(RESULT_FILE))\n",
    "    with open(RESULT_FILE.format(model_name), 'w') as file:\n",
    "        json.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printResult(model_name=None):\n",
    "\n",
    "    results = json.load(open(RESULT_FILE.format(model_name), \"rb\"))\n",
    "\n",
    "    weighted_precision, weighted_recall = [], []\n",
    "    weighted_fscores = []\n",
    "\n",
    "    print(\"#\"*20)\n",
    "    for fold, result in enumerate(results):\n",
    "        weighted_fscores.append(result[\"weighted avg\"][\"f1-score\"])\n",
    "        weighted_precision.append(result[\"weighted avg\"][\"precision\"])\n",
    "        weighted_recall.append(result[\"weighted avg\"][\"recall\"])\n",
    "\n",
    "        print(\"Fold {}:\".format(fold+1))\n",
    "        print(\"Weighted Precision: {}  Weighted Recall: {}  Weighted F score: {}\".format(result[\"weighted avg\"][\"precision\"],\n",
    "                                                                                         result[\"weighted avg\"][\"recall\"],\n",
    "                                                                                         result[\"weighted avg\"][\"f1-score\"]))\n",
    "    print(\"#\"*20)\n",
    "    print(\"Avg :\")\n",
    "    print(\"Weighted Precision: {:.3f}  Weighted Recall: {:.3f}  Weighted F score: {:.3f}\".format(np.mean(weighted_precision),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    if config.speaker_independent:\n",
    "        trainSpeakerIndependent(model_name=config.model)\n",
    "    else:\n",
    "        for _ in range(config.runs):\n",
    "            trainSpeakerDependent(model_name=config.model)\n",
    "            printResult(model_name=config.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
